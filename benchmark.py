"""
å¯¹æ¯”å®éªŒæ¡†æ¶
åŒæ—¶è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªæ¨¡å‹ï¼šPure Mamba, Pure MinGRU, Hybrid Mamba-GRU
"""
import numpy as np
import sys
import os
import json
import time
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(__file__))

from models import Mamba, MinGRU, MambaGRU
from utils.data_loader import load_yahoo_stock, create_sequences, split_data, batch_generator
from utils.optimizers import AdamOptimizer
from utils.schedulers import CosineAnnealingLR
from utils.regularization import gradient_clipping, l2_regularization_loss, l2_regularization_grad, EarlyStopping
from utils.metrics import compute_all_metrics
from train import train_model, evaluate_model


def run_benchmark(seq_len=60, hidden_size=64, state_size=64,
                  epochs=100, batch_size=32, learning_rate=0.001,
                  use_mock_data=False, save_results=True):
    """
    è¿è¡Œå¯¹æ¯”å®éªŒ
    
    å‚æ•°:
        seq_len: int, è¾“å…¥åºåˆ—é•¿åº¦
        hidden_size: int, éšè—å±‚ç»´åº¦
        state_size: int, Mamba çš„çŠ¶æ€ç©ºé—´ç»´åº¦
        epochs: int, è®­ç»ƒè½®æ•°
        batch_size: int, æ‰¹æ¬¡å¤§å°
        learning_rate: float, å­¦ä¹ ç‡
        use_mock_data: bool, æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        save_results: bool, æ˜¯å¦ä¿å­˜ç»“æœ
    
    è¿”å›:
        results: dict, åŒ…å«æ‰€æœ‰æ¨¡å‹çš„ç»“æœ
    """
    print("\n" + "=" * 100)
    print("MAMBA-GRU æ··åˆæ¶æ„å¯¹æ¯”å®éªŒ")
    print("=" * 100)
    print(f"å®éªŒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"åºåˆ—é•¿åº¦: {seq_len}")
    print(f"éšè—å±‚ç»´åº¦: {hidden_size}")
    print(f"è®­ç»ƒè½®æ•°: {epochs}")
    print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"å­¦ä¹ ç‡: {learning_rate}")
    print("=" * 100 + "\n")
    
    # ========== 1. åŠ è½½å’Œé¢„å¤„ç†æ•°æ® ==========
    print("æ­¥éª¤ 1: åŠ è½½æ•°æ®...")
    data_scaled, scaler, raw_data = load_yahoo_stock(ticker='AAPL', use_mock_data=use_mock_data)
    
    print(f"\næ­¥éª¤ 2: åˆ›å»ºåºåˆ— (seq_len={seq_len})...")
    X, y = create_sequences(data_scaled, seq_len=seq_len)
    
    print(f"\næ­¥éª¤ 3: åˆ’åˆ†æ•°æ®...")
    X_train, y_train, X_val, y_val, X_test, y_test = split_data(
        X, y, train_ratio=0.7, val_ratio=0.15
    )
    
    # å­˜å‚¨æ‰€æœ‰æ¨¡å‹çš„ç»“æœ
    results = {
        'metadata': {
            'seq_len': seq_len,
            'hidden_size': hidden_size,
            'state_size': state_size,
            'epochs': epochs,
            'batch_size': batch_size,
            'learning_rate': learning_rate,
            'train_samples': len(X_train),
            'val_samples': len(X_val),
            'test_samples': len(X_test)
        },
        'models': {}
    }
    
    # å®šä¹‰è¦å¯¹æ¯”çš„æ¨¡å‹
    model_configs = [
        {
            'name': 'Pure Mamba',
            'model_class': Mamba,
            'params': {
                'input_size': 1,
                'hidden_size': hidden_size,
                'output_size': 1,
                'state_size': state_size,
                'seed': 42
            }
        },
        {
            'name': 'Pure MinGRU',
            'model_class': MinGRU,
            'params': {
                'input_size': 1,
                'hidden_size': hidden_size,
                'output_size': 1,
                'seed': 42
            }
        },
        {
            'name': 'Hybrid Mamba-GRU',
            'model_class': MambaGRU,
            'params': {
                'input_size': 1,
                'hidden_size': hidden_size,
                'output_size': 1,
                'state_size': state_size,
                'use_vector_alpha': False,
                'seed': 42
            }
        }
    ]
    
    # ========== 2. è®­ç»ƒå’Œè¯„ä¼°æ¯ä¸ªæ¨¡å‹ ==========
    for config in model_configs:
        model_name = config['name']
        print("\n" + "=" * 100)
        print(f"è®­ç»ƒæ¨¡å‹: {model_name}")
        print("=" * 100)
        
        # åˆå§‹åŒ–æ¨¡å‹
        model = config['model_class'](**config['params'])
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        optimizer = AdamOptimizer(learning_rate=learning_rate, beta1=0.9, beta2=0.999)
        scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=learning_rate * 0.01)
        
        # è®­ç»ƒæ¨¡å‹
        start_time = time.time()
        history = train_model(
            model=model,
            X_train=X_train,
            y_train=y_train,
            X_val=X_val,
            y_val=y_val,
            optimizer=optimizer,
            scheduler=scheduler,
            epochs=epochs,
            batch_size=batch_size,
            gradient_clip_norm=5.0,
            l2_lambda=0.0001,
            early_stopping_patience=20,
            verbose=True
        )
        training_time = time.time() - start_time
        
        # è¯„ä¼°æ¨¡å‹
        predictions, metrics = evaluate_model(
            model=model,
            X_test=X_test,
            y_test=y_test,
            scaler=scaler,
            batch_size=batch_size
        )
        
        # ä¿å­˜ç»“æœ
        results['models'][model_name] = {
            'history': history,
            'metrics': metrics,
            'training_time': training_time,
            'predictions': predictions.tolist() if save_results else None
        }
        
        # å¦‚æœæ˜¯æ··åˆæ¨¡å‹ï¼Œä¿å­˜ alpha å†å²
        if hasattr(model, 'alpha_history'):
            results['models'][model_name]['alpha_history'] = model.alpha_history
            results['models'][model_name]['final_alpha'] = float(np.mean(model.get_fusion_weight()))
    
    # ========== 3. æ‰“å°å¯¹æ¯”ç»“æœ ==========
    print("\n" + "=" * 100)
    print("å¯¹æ¯”å®éªŒç»“æœæ±‡æ€»")
    print("=" * 100)
    
    # æ‰“å° Markdown è¡¨æ ¼
    print("\n## æµ‹è¯•é›†è¯„ä»·æŒ‡æ ‡å¯¹æ¯”\n")
    print("| æ¨¡å‹ | MSE | RMSE | MAE | RÂ² | MAPE (%) | è®­ç»ƒæ—¶é—´ (s) |")
    print("|------|-----|------|-----|-----|----------|--------------|")
    
    for model_name in ['Pure Mamba', 'Pure MinGRU', 'Hybrid Mamba-GRU']:
        metrics = results['models'][model_name]['metrics']
        train_time = results['models'][model_name]['training_time']
        print(f"| {model_name} | "
              f"{metrics['MSE']:.6f} | "
              f"{metrics['RMSE']:.6f} | "
              f"{metrics['MAE']:.6f} | "
              f"{metrics['R2']:.6f} | "
              f"{metrics['MAPE']:.2f} | "
              f"{train_time:.2f} |")
    
    print("\n" + "=" * 100)
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    best_model = min(results['models'].items(), key=lambda x: x[1]['metrics']['MSE'])
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model[0]}")
    print(f"   æµ‹è¯•é›† MSE: {best_model[1]['metrics']['MSE']:.6f}")
    print(f"   æµ‹è¯•é›† RÂ²: {best_model[1]['metrics']['R2']:.6f}")
    
    # å¦‚æœæ˜¯æ··åˆæ¨¡å‹ï¼Œæ‰“å°èåˆæƒé‡
    if 'Hybrid Mamba-GRU' in results['models']:
        final_alpha = results['models']['Hybrid Mamba-GRU'].get('final_alpha', None)
        if final_alpha is not None:
            print(f"\nğŸ“Š æ··åˆæ¨¡å‹æœ€ç»ˆèåˆæƒé‡:")
            print(f"   Mamba: {final_alpha:.4f}")
            print(f"   GRU:   {1 - final_alpha:.4f}")
    
    print("\n" + "=" * 100 + "\n")
    
    # ========== 4. ä¿å­˜ç»“æœ ==========
    if save_results:
        results_dir = os.path.join(os.path.dirname(__file__), 'results')
        os.makedirs(results_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        results_file = os.path.join(results_dir, f'benchmark_results_{timestamp}.json')
        
        # ä¿å­˜ä¸º JSON (éœ€è¦è½¬æ¢ numpy ç±»å‹)
        def convert_to_serializable(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, dict):
                return {k: convert_to_serializable(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_to_serializable(item) for item in obj]
            else:
                return obj
        
        results_serializable = convert_to_serializable(results)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results_serializable, f, indent=2, ensure_ascii=False)
        
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    return results


if __name__ == "__main__":
    # è¿è¡Œå¯¹æ¯”å®éªŒ
    results = run_benchmark(
        seq_len=60,
        hidden_size=64,
        state_size=64,
        epochs=100,
        batch_size=32,
        learning_rate=0.001,
        use_mock_data=True,  # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä»¥ä¾¿å¿«é€Ÿæµ‹è¯•
        save_results=True
    )
    
    print("\nå¯¹æ¯”å®éªŒå®Œæˆï¼")
